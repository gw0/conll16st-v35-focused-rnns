[2018-03-12 11:16] configuration (ex/conll16st-vsimple-en)
[2018-03-12 11:16]   config 'arg1_len': 100
[2018-03-12 11:16]   config 'arg2_len': 100
[2018-03-12 11:16]   config 'backend': theano
[2018-03-12 11:16]   config 'backend_theano': device=gpu,floatX=float32,nvcc.fastmath=True,lib.cnmem=1
[2018-03-12 11:16]   config 'batch_size': 64
[2018-03-12 11:16]   config 'conn_len': 10
[2018-03-12 11:16]   config 'continue_': False
[2018-03-12 11:16]   config 'curriculum_end': 0.0
[2018-03-12 11:16]   config 'epochs': 1000
[2018-03-12 11:16]   config 'epochs_patience': 100
[2018-03-12 11:16]   config 'epochs_ratio': 0.1
[2018-03-12 11:16]   config 'filter_fn_name': None
[2018-03-12 11:16]   config 'final_act': SReLU
[2018-03-12 11:16]   config 'final_dim': 0
[2018-03-12 11:16]   config 'final_dropout': 0.3
[2018-03-12 11:16]   config 'lang': en
[2018-03-12 11:16]   config 'masking': True
[2018-03-12 11:16]   config 'mode': word
[2018-03-12 11:16]   config 'model_dir': ex/conll16st-vsimple-en
[2018-03-12 11:16]   config 'optimizer': adam
[2018-03-12 11:16]   config 'original_positives': 0
[2018-03-12 11:16]   config 'punc_len': 0
[2018-03-12 11:16]   config 'random_negatives': 2
[2018-03-12 11:16]   config 'random_positives': 2
[2018-03-12 11:16]   config 'random_proba_1': 0.1
[2018-03-12 11:16]   config 'random_proba_2': 0.1
[2018-03-12 11:16]   config 'random_proba_3': 0.9
[2018-03-12 11:16]   config 'rnn_act': tanh
[2018-03-12 11:16]   config 'rnn_dim': 160
[2018-03-12 11:16]   config 'rnn_dropout_U': 0.0
[2018-03-12 11:16]   config 'rnn_dropout_W': 0.0
[2018-03-12 11:16]   config 'rnn_num': 1
[2018-03-12 11:16]   config 'rnn_shared': none
[2018-03-12 11:16]   config 'rnn_type': lstm-fwd
[2018-03-12 11:16]   config 'rnn_zoneout_c': 0.0
[2018-03-12 11:16]   config 'rnn_zoneout_h': 0.0
[2018-03-12 11:16]   config 'snapshot_size': 2048
[2018-03-12 11:16]   config 'train_dir': data/conll16st-en-03-29-16-train
[2018-03-12 11:16]   config 'valid_dir': data/conll16st-en-03-29-16-dev
[2018-03-12 11:16]   config 'words2vec_bin': None
[2018-03-12 11:16]   config 'words2vec_txt': None
[2018-03-12 11:16]   config 'words_dim': 20
[2018-03-12 11:16]   config 'words_dropout': 0.3
[2018-03-12 11:16]   config 'words_shared': global
[2018-03-12 11:16]   config 'words_trainable': True
[2018-03-12 11:16] load dataset for training (data/conll16st-en-03-29-16-train)
[2018-03-12 11:25]   lang: en, doc_ids: 1756, words: 933049, rel_ids: 32535, relation tokens: 1159204
[2018-03-12 11:25] load dataset for validation (data/conll16st-en-03-29-16-dev)
[2018-03-12 11:26]   lang: en, doc_ids: 79, words: 39712, rel_ids: 1436, relation tokens: 48882
[2018-03-12 11:26] build indexes from training
[2018-03-12 11:26]   words2id: 43918, target2id: 23
[2018-03-12 11:26] target class distribution from training
[2018-03-12 11:26]   class 0 = 'None': None
[2018-03-12 11:26]   class 1 = '': None
[2018-03-12 11:26]   class 2 = 'Expansion.Conjunction': 7817
[2018-03-12 11:26]   class 3 = 'Comparison.Contrast': 4714
[2018-03-12 11:26]   class 4 = 'EntRel': 4133
[2018-03-12 11:26]   class 5 = 'Contingency.Cause.Reason': 3344
[2018-03-12 11:26]   class 6 = 'Expansion.Restatement': 2699
[2018-03-12 11:26]   class 7 = 'Contingency.Cause.Result': 2137
[2018-03-12 11:26]   class 8 = 'Temporal.Synchrony': 1499
[2018-03-12 11:26]   class 9 = 'Expansion.Instantiation': 1403
[2018-03-12 11:26]   class 10 = 'Comparison.Concession': 1293
[2018-03-12 11:26]   class 11 = 'Temporal.Asynchronous.Precedence': 1277
[2018-03-12 11:26]   class 12 = 'Contingency.Condition': 1197
[2018-03-12 11:26]   class 13 = 'Temporal.Asynchronous.Succession': 1014
[2018-03-12 11:26]   class 14 = 'Comparison': 992
[2018-03-12 11:26]   class 15 = 'Expansion': 630
[2018-03-12 11:26]   class 16 = 'Expansion.Alternative.Chosen alternative': 241
[2018-03-12 11:26]   class 17 = 'Expansion.Alternative': 210
[2018-03-12 11:26]   class 18 = 'Temporal': 27
[2018-03-12 11:26]   class 19 = 'Contingency': 24
[2018-03-12 11:26]   class 20 = 'Expansion.Exception': 15
[2018-03-12 11:26]   class 21 = 'Temporal.Asynchronous': 6
[2018-03-12 11:26]   class 22 = 'Contingency.Cause': 2
[2018-03-12 11:26] build model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
arg1_ids (InputLayer)            (None, 100)           0                                            
____________________________________________________________________________________________________
arg2_ids (InputLayer)            (None, 100)           0                                            
____________________________________________________________________________________________________
conn_ids (InputLayer)            (None, 10)            0                                            
____________________________________________________________________________________________________
embedding_1 (Embedding)          multiple              878360      arg1_ids[0][0]                   
                                                                   arg2_ids[0][0]                   
                                                                   conn_ids[0][0]                   
____________________________________________________________________________________________________
shareablelstm_1 (ShareableLSTM)  (None, 160)           115840      embedding_1[0][0]                
____________________________________________________________________________________________________
shareablelstm_3 (ShareableLSTM)  (None, 160)           115840      embedding_1[1][0]                
____________________________________________________________________________________________________
shareablelstm_5 (ShareableLSTM)  (None, 160)           115840      embedding_1[2][0]                
____________________________________________________________________________________________________
merge_1 (Merge)                  (None, 480)           0           shareablelstm_1[0][0]            
                                                                   shareablelstm_3[0][0]            
                                                                   shareablelstm_5[0][0]            
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 23)            11063       merge_1[0][0]                    
____________________________________________________________________________________________________
target (Activation)              (None, 23)            0           dense_1[0][0]                    
====================================================================================================
Total params: 1,236,943
Trainable params: 1,236,943
Non-trainable params: 0
____________________________________________________________________________________________________
[2018-03-12 11:27] initialize weights
[2018-03-12 11:27] training preparation
[2018-03-12 11:27] train model (ex/conll16st-vsimple-en)
Epoch 1/1000
12992/13056 [============================>.] - ETA: 0s - loss: 1.8035
- val_loss: 2.1328
- val_all_f1:  0.4290 0.4290 0.4290
- val_exp_f1:  0.5675 0.5675 0.5675
- val_non_f1:  0.3071 0.3071 0.3071

13056/13056 [==============================] - 73s - loss: 1.8011 - val_loss: 2.1328
Epoch 2/1000
12992/13056 [============================>.] - ETA: 0s - loss: 1.0870
- val_loss: 1.8472
- val_all_f1:  0.4425 0.4425 0.4425
- val_exp_f1:  0.7223 0.7223 0.7223
- val_non_f1:  0.1963 0.1963 0.1963

13056/13056 [==============================] - 70s - loss: 1.0860 - val_loss: 1.8472
Epoch 3/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.9787
- val_loss: 1.6692
- val_all_f1:  0.5334 0.5334 0.5334
- val_exp_f1:  0.7906 0.7906 0.7906
- val_non_f1:  0.3071 0.3071 0.3071

13056/13056 [==============================] - 72s - loss: 0.9783 - val_loss: 1.6692
Epoch 4/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.9493
- val_loss: 1.5976
- val_all_f1:  0.5568 0.5568 0.5568
- val_exp_f1:  0.8604 0.8604 0.8604
- val_non_f1:  0.2897 0.2897 0.2897

13056/13056 [==============================] - 76s - loss: 0.9484 - val_loss: 1.5976
Epoch 5/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.9185
- val_loss: 1.5441
- val_all_f1:  0.5710 0.5710 0.5710
- val_exp_f1:  0.8741 0.8741 0.8741
- val_non_f1:  0.3048 0.3044 0.3046

13056/13056 [==============================] - 69s - loss: 0.9181 - val_loss: 1.5441
Epoch 6/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8945
- val_loss: 1.5140
- val_all_f1:  0.5291 0.5291 0.5291
- val_exp_f1:  0.8695 0.8695 0.8695
- val_non_f1:  0.2296 0.2296 0.2296

13056/13056 [==============================] - 75s - loss: 0.8951 - val_loss: 1.5140
Epoch 7/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8822
- val_loss: 1.4715
- val_all_f1:  0.5916 0.5916 0.5916
- val_exp_f1:  0.8938 0.8938 0.8938
- val_non_f1:  0.3258 0.3258 0.3258

13056/13056 [==============================] - 78s - loss: 0.8824 - val_loss: 1.4715
Epoch 8/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8822
- val_loss: 1.4714
- val_all_f1:  0.5909 0.5909 0.5909
- val_exp_f1:  0.8953 0.8953 0.8953
- val_non_f1:  0.3231 0.3231 0.3231

13056/13056 [==============================] - 81s - loss: 0.8811 - val_loss: 1.4714
Epoch 9/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8754
- val_loss: 1.4307
- val_all_f1:  0.6065 0.6065 0.6065
- val_exp_f1:  0.9044 0.9044 0.9044
- val_non_f1:  0.3445 0.3445 0.3445

13056/13056 [==============================] - 73s - loss: 0.8753 - val_loss: 1.4307
Epoch 10/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8488
- val_loss: 1.4469
- val_all_f1:  0.5909 0.5909 0.5909
- val_exp_f1:  0.8953 0.8953 0.8953
- val_non_f1:  0.3231 0.3231 0.3231

13056/13056 [==============================] - 77s - loss: 0.8490 - val_loss: 1.4469
Epoch 11/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8454
- val_loss: 1.4364
- val_all_f1:  0.5866 0.5866 0.5866
- val_exp_f1:  0.8983 0.8983 0.8983
- val_non_f1:  0.3124 0.3124 0.3124

13056/13056 [==============================] - 74s - loss: 0.8459 - val_loss: 1.4364
Epoch 12/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8291
- val_loss: 1.4074
- val_all_f1:  0.5845 0.5845 0.5845
- val_exp_f1:  0.8938 0.8938 0.8938
- val_non_f1:  0.3124 0.3124 0.3124

13056/13056 [==============================] - 73s - loss: 0.8298 - val_loss: 1.4074
Epoch 13/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8249
- val_loss: 1.3965
- val_all_f1:  0.6030 0.6030 0.6030
- val_exp_f1:  0.9044 0.9044 0.9044
- val_non_f1:  0.3378 0.3378 0.3378

13056/13056 [==============================] - 76s - loss: 0.8240 - val_loss: 1.3965
Epoch 14/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8356
- val_loss: 1.3928
- val_all_f1:  0.6009 0.6009 0.6009
- val_exp_f1:  0.8968 0.8968 0.8968
- val_non_f1:  0.3405 0.3405 0.3405

13056/13056 [==============================] - 73s - loss: 0.8341 - val_loss: 1.3928
Epoch 15/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8273
- val_loss: 1.3695
- val_all_f1:  0.5902 0.5902 0.5902
- val_exp_f1:  0.9059 0.9059 0.9059
- val_non_f1:  0.3124 0.3124 0.3124

13056/13056 [==============================] - 74s - loss: 0.8276 - val_loss: 1.3695
Epoch 16/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8573
- val_loss: 1.3777
- val_all_f1:  0.5874 0.5874 0.5874
- val_exp_f1:  0.8953 0.8953 0.8953
- val_non_f1:  0.3164 0.3164 0.3164

13056/13056 [==============================] - 77s - loss: 0.8575 - val_loss: 1.3777
Epoch 17/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8247
- val_loss: 1.3983
- val_all_f1:  0.5909 0.5909 0.5909
- val_exp_f1:  0.8998 0.8998 0.8998
- val_non_f1:  0.3191 0.3191 0.3191

13056/13056 [==============================] - 73s - loss: 0.8247 - val_loss: 1.3983
Epoch 18/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8044
- val_loss: 1.3695
- val_all_f1:  0.5980 0.5980 0.5980
- val_exp_f1:  0.9059 0.9059 0.9059
- val_non_f1:  0.3271 0.3271 0.3271

13056/13056 [==============================] - 75s - loss: 0.8042 - val_loss: 1.3695
Epoch 19/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8137
- val_loss: 1.3643
- val_all_f1:  0.6023 0.6023 0.6023
- val_exp_f1:  0.8983 0.8983 0.8983
- val_non_f1:  0.3418 0.3418 0.3418

13056/13056 [==============================] - 74s - loss: 0.8134 - val_loss: 1.3643
Epoch 20/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.8180
- val_loss: 1.3746
- val_all_f1:  0.5838 0.5838 0.5838
- val_exp_f1:  0.9044 0.9044 0.9044
- val_non_f1:  0.3017 0.3017 0.3017

13056/13056 [==============================] - 73s - loss: 0.8174 - val_loss: 1.3746
Epoch 21/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7754
- val_loss: 1.3734
- val_all_f1:  0.5930 0.5930 0.5930
- val_exp_f1:  0.8816 0.8816 0.8816
- val_non_f1:  0.3391 0.3391 0.3391

13056/13056 [==============================] - 76s - loss: 0.7748 - val_loss: 1.3734
Epoch 22/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7625
- val_loss: 1.3534
- val_all_f1:  0.6122 0.6122 0.6122
- val_exp_f1:  0.9029 0.9029 0.9029
- val_non_f1:  0.3565 0.3565 0.3565

13056/13056 [==============================] - 69s - loss: 0.7630 - val_loss: 1.3534
Epoch 23/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7851
- val_loss: 1.4047
- val_all_f1:  0.5781 0.5781 0.5781
- val_exp_f1:  0.9044 0.9044 0.9044
- val_non_f1:  0.2911 0.2911 0.2911

13056/13056 [==============================] - 70s - loss: 0.7858 - val_loss: 1.4047
Epoch 24/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7763
- val_loss: 1.3901
- val_all_f1:  0.5788 0.5788 0.5788
- val_exp_f1:  0.8832 0.8832 0.8832
- val_non_f1:  0.3111 0.3111 0.3111

13056/13056 [==============================] - 70s - loss: 0.7782 - val_loss: 1.3901
Epoch 25/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7830
- val_loss: 1.3905
- val_all_f1:  0.5845 0.5845 0.5845
- val_exp_f1:  0.8923 0.8923 0.8923
- val_non_f1:  0.3138 0.3138 0.3138

13056/13056 [==============================] - 69s - loss: 0.7831 - val_loss: 1.3905
Epoch 26/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7558
- val_loss: 1.3510
- val_all_f1:  0.6072 0.6072 0.6072
- val_exp_f1:  0.9014 0.9014 0.9014
- val_non_f1:  0.3485 0.3485 0.3485

13056/13056 [==============================] - 74s - loss: 0.7559 - val_loss: 1.3510
Epoch 27/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7870
- val_loss: 1.4021
- val_all_f1:  0.5845 0.5845 0.5845
- val_exp_f1:  0.9059 0.9059 0.9059
- val_non_f1:  0.3017 0.3017 0.3017

13056/13056 [==============================] - 77s - loss: 0.7858 - val_loss: 1.4021
Epoch 28/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7544
- val_loss: 1.3621
- val_all_f1:  0.6229 0.6229 0.6229
- val_exp_f1:  0.9120 0.9120 0.9120
- val_non_f1:  0.3685 0.3685 0.3685

13056/13056 [==============================] - 74s - loss: 0.7544 - val_loss: 1.3621
Epoch 29/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7756
- val_loss: 1.3848
- val_all_f1:  0.6072 0.6072 0.6072
- val_exp_f1:  0.8953 0.8953 0.8953
- val_non_f1:  0.3538 0.3538 0.3538

13056/13056 [==============================] - 67s - loss: 0.7752 - val_loss: 1.3848
Epoch 30/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7956
- val_loss: 1.3663
- val_all_f1:  0.6030 0.6030 0.6030
- val_exp_f1:  0.9044 0.9044 0.9044
- val_non_f1:  0.3378 0.3378 0.3378

13056/13056 [==============================] - 76s - loss: 0.7948 - val_loss: 1.3663
Epoch 31/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6800
- val_loss: 1.4654
- val_all_f1:  0.5632 0.5632 0.5632
- val_exp_f1:  0.8983 0.8983 0.8983
- val_non_f1:  0.2684 0.2684 0.2684

13056/13056 [==============================] - 71s - loss: 0.6796 - val_loss: 1.4654
Epoch 32/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7260
- val_loss: 1.4229
- val_all_f1:  0.6009 0.6009 0.6009
- val_exp_f1:  0.9090 0.9090 0.9090
- val_non_f1:  0.3298 0.3298 0.3298

13056/13056 [==============================] - 74s - loss: 0.7266 - val_loss: 1.4229
Epoch 33/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6923
- val_loss: 1.4191
- val_all_f1:  0.6094 0.6094 0.6094
- val_exp_f1:  0.9059 0.9059 0.9059
- val_non_f1:  0.3485 0.3485 0.3485

13056/13056 [==============================] - 74s - loss: 0.6931 - val_loss: 1.4191
Epoch 34/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7135
- val_loss: 1.4064
- val_all_f1:  0.6037 0.6037 0.6037
- val_exp_f1:  0.9029 0.9029 0.9029
- val_non_f1:  0.3405 0.3405 0.3405

13056/13056 [==============================] - 71s - loss: 0.7122 - val_loss: 1.4064
Epoch 35/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6990
- val_loss: 1.4028
- val_all_f1:  0.6065 0.6065 0.6065
- val_exp_f1:  0.9074 0.9074 0.9074
- val_non_f1:  0.3418 0.3418 0.3418

13056/13056 [==============================] - 69s - loss: 0.6995 - val_loss: 1.4028
Epoch 36/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7177
- val_loss: 1.4131
- val_all_f1:  0.5923 0.5923 0.5923
- val_exp_f1:  0.8877 0.8877 0.8877
- val_non_f1:  0.3324 0.3324 0.3324

13056/13056 [==============================] - 68s - loss: 0.7174 - val_loss: 1.4131
Epoch 37/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7173
- val_loss: 1.3944
- val_all_f1:  0.6001 0.6001 0.6001
- val_exp_f1:  0.8983 0.8983 0.8983
- val_non_f1:  0.3378 0.3378 0.3378

13056/13056 [==============================] - 70s - loss: 0.7183 - val_loss: 1.3944
Epoch 38/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7051
- val_loss: 1.4092
- val_all_f1:  0.5902 0.5902 0.5902
- val_exp_f1:  0.8847 0.8847 0.8847
- val_non_f1:  0.3311 0.3311 0.3311

13056/13056 [==============================] - 77s - loss: 0.7047 - val_loss: 1.4092
Epoch 39/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.7010
- val_loss: 1.3940
- val_all_f1:  0.6108 0.6108 0.6108
- val_exp_f1:  0.9044 0.9044 0.9044
- val_non_f1:  0.3525 0.3525 0.3525

13056/13056 [==============================] - 71s - loss: 0.6997 - val_loss: 1.3940
Epoch 40/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6969
- val_loss: 1.4143
- val_all_f1:  0.6023 0.6023 0.6023
- val_exp_f1:  0.8877 0.8877 0.8877
- val_non_f1:  0.3511 0.3511 0.3511

13056/13056 [==============================] - 74s - loss: 0.6975 - val_loss: 1.4143
Epoch 41/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6281
- val_loss: 1.4399
- val_all_f1:  0.5930 0.5930 0.5930
- val_exp_f1:  0.8998 0.8998 0.8998
- val_non_f1:  0.3231 0.3231 0.3231

13056/13056 [==============================] - 76s - loss: 0.6302 - val_loss: 1.4399
Epoch 42/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6189
- val_loss: 1.4489
- val_all_f1:  0.5923 0.5923 0.5923
- val_exp_f1:  0.8983 0.8983 0.8983
- val_non_f1:  0.3231 0.3231 0.3231

13056/13056 [==============================] - 71s - loss: 0.6187 - val_loss: 1.4489
Epoch 43/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6091
- val_loss: 1.4638
- val_all_f1:  0.6030 0.6030 0.6030
- val_exp_f1:  0.8877 0.8877 0.8877
- val_non_f1:  0.3525 0.3525 0.3525

13056/13056 [==============================] - 68s - loss: 0.6086 - val_loss: 1.4638
Epoch 44/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6246
- val_loss: 1.5107
- val_all_f1:  0.5952 0.5952 0.5952
- val_exp_f1:  0.8907 0.8907 0.8907
- val_non_f1:  0.3351 0.3351 0.3351

13056/13056 [==============================] - 72s - loss: 0.6243 - val_loss: 1.5107
Epoch 45/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6243
- val_loss: 1.5072
- val_all_f1:  0.5881 0.5881 0.5881
- val_exp_f1:  0.8983 0.8983 0.8983
- val_non_f1:  0.3151 0.3151 0.3151

13056/13056 [==============================] - 72s - loss: 0.6243 - val_loss: 1.5072
Epoch 46/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6447
- val_loss: 1.5214
- val_all_f1:  0.5717 0.5717 0.5717
- val_exp_f1:  0.8665 0.8665 0.8665
- val_non_f1:  0.3124 0.3124 0.3124

13056/13056 [==============================] - 73s - loss: 0.6444 - val_loss: 1.5214
Epoch 47/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6095
- val_loss: 1.4974
- val_all_f1:  0.5881 0.5881 0.5881
- val_exp_f1:  0.8725 0.8725 0.8725
- val_non_f1:  0.3378 0.3378 0.3378

13056/13056 [==============================] - 68s - loss: 0.6094 - val_loss: 1.4974
Epoch 48/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6468
- val_loss: 1.4938
- val_all_f1:  0.5845 0.5845 0.5845
- val_exp_f1:  0.8710 0.8710 0.8710
- val_non_f1:  0.3324 0.3324 0.3324

13056/13056 [==============================] - 78s - loss: 0.6460 - val_loss: 1.4938
Epoch 49/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6060
- val_loss: 1.4937
- val_all_f1:  0.5817 0.5817 0.5817
- val_exp_f1:  0.8832 0.8832 0.8832
- val_non_f1:  0.3164 0.3164 0.3164

13056/13056 [==============================] - 73s - loss: 0.6061 - val_loss: 1.4937
Epoch 50/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.6115
- val_loss: 1.5303
- val_all_f1:  0.5923 0.5923 0.5923
- val_exp_f1:  0.8923 0.8923 0.8923
- val_non_f1:  0.3284 0.3284 0.3284

13056/13056 [==============================] - 71s - loss: 0.6109 - val_loss: 1.5303
Epoch 51/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5210
- val_loss: 1.5558
- val_all_f1:  0.5888 0.5888 0.5888
- val_exp_f1:  0.8953 0.8953 0.8953
- val_non_f1:  0.3191 0.3191 0.3191

13056/13056 [==============================] - 84s - loss: 0.5197 - val_loss: 1.5558
Epoch 52/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5171
- val_loss: 1.5781
- val_all_f1:  0.5781 0.5781 0.5781
- val_exp_f1:  0.8756 0.8756 0.8756
- val_non_f1:  0.3164 0.3164 0.3164

13056/13056 [==============================] - 75s - loss: 0.5169 - val_loss: 1.5781
Epoch 53/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5268
- val_loss: 1.5539
- val_all_f1:  0.5916 0.5916 0.5916
- val_exp_f1:  0.8832 0.8832 0.8832
- val_non_f1:  0.3351 0.3351 0.3351

13056/13056 [==============================] - 73s - loss: 0.5275 - val_loss: 1.5539
Epoch 54/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5397
- val_loss: 1.5769
- val_all_f1:  0.5810 0.5810 0.5810
- val_exp_f1:  0.8847 0.8847 0.8847
- val_non_f1:  0.3138 0.3138 0.3138

13056/13056 [==============================] - 67s - loss: 0.5396 - val_loss: 1.5769
Epoch 55/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5274
- val_loss: 1.5928
- val_all_f1:  0.5724 0.5724 0.5724
- val_exp_f1:  0.8619 0.8619 0.8619
- val_non_f1:  0.3178 0.3178 0.3178

13056/13056 [==============================] - 66s - loss: 0.5289 - val_loss: 1.5928
Epoch 56/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5181
- val_loss: 1.5901
- val_all_f1:  0.5859 0.5859 0.5859
- val_exp_f1:  0.8710 0.8710 0.8710
- val_non_f1:  0.3351 0.3351 0.3351

13056/13056 [==============================] - 78s - loss: 0.5185 - val_loss: 1.5901
Epoch 57/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5660
- val_loss: 1.5686
- val_all_f1:  0.5781 0.5781 0.5781
- val_exp_f1:  0.8710 0.8710 0.8710
- val_non_f1:  0.3204 0.3204 0.3204

13056/13056 [==============================] - 76s - loss: 0.5660 - val_loss: 1.5686
Epoch 58/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5634
- val_loss: 1.6022
- val_all_f1:  0.5653 0.5653 0.5653
- val_exp_f1:  0.8589 0.8589 0.8589
- val_non_f1:  0.3071 0.3071 0.3071

13056/13056 [==============================] - 68s - loss: 0.5629 - val_loss: 1.6022
Epoch 59/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5655
- val_loss: 1.6040
- val_all_f1:  0.5589 0.5589 0.5589
- val_exp_f1:  0.8604 0.8604 0.8604
- val_non_f1:  0.2937 0.2937 0.2937

13056/13056 [==============================] - 80s - loss: 0.5637 - val_loss: 1.6040
Epoch 60/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.5242
- val_loss: 1.5992
- val_all_f1:  0.5746 0.5746 0.5746
- val_exp_f1:  0.8756 0.8756 0.8756
- val_non_f1:  0.3102 0.3097 0.3100

13056/13056 [==============================] - 81s - loss: 0.5231 - val_loss: 1.5992
Epoch 61/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4581
- val_loss: 1.7070
- val_all_f1:  0.5483 0.5483 0.5483
- val_exp_f1:  0.8422 0.8422 0.8422
- val_non_f1:  0.2901 0.2897 0.2899

13056/13056 [==============================] - 74s - loss: 0.4579 - val_loss: 1.7070
Epoch 62/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4577
- val_loss: 1.6859
- val_all_f1:  0.5589 0.5589 0.5589
- val_exp_f1:  0.8558 0.8558 0.8558
- val_non_f1:  0.2981 0.2977 0.2979

13056/13056 [==============================] - 76s - loss: 0.4588 - val_loss: 1.6859
Epoch 63/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4631
- val_loss: 1.7147
- val_all_f1:  0.5455 0.5455 0.5455
- val_exp_f1:  0.8361 0.8361 0.8361
- val_non_f1:  0.2901 0.2897 0.2899

13056/13056 [==============================] - 68s - loss: 0.4633 - val_loss: 1.7147
Epoch 64/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4824
- val_loss: 1.6955
- val_all_f1:  0.5526 0.5526 0.5526
- val_exp_f1:  0.8392 0.8392 0.8392
- val_non_f1:  0.3008 0.3004 0.3006

13056/13056 [==============================] - 70s - loss: 0.4843 - val_loss: 1.6955
Epoch 65/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4436
- val_loss: 1.7002
- val_all_f1:  0.5398 0.5398 0.5398
- val_exp_f1:  0.8407 0.8407 0.8407
- val_non_f1:  0.2754 0.2750 0.2752

13056/13056 [==============================] - 66s - loss: 0.4432 - val_loss: 1.7002
Epoch 66/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4748
- val_loss: 1.6769
- val_all_f1:  0.5689 0.5689 0.5689
- val_exp_f1:  0.8574 0.8574 0.8574
- val_non_f1:  0.3155 0.3151 0.3153

13056/13056 [==============================] - 68s - loss: 0.4740 - val_loss: 1.6769
Epoch 67/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4721
- val_loss: 1.6755
- val_all_f1:  0.5724 0.5724 0.5724
- val_exp_f1:  0.8604 0.8604 0.8604
- val_non_f1:  0.3191 0.3191 0.3191

13056/13056 [==============================] - 73s - loss: 0.4717 - val_loss: 1.6755
Epoch 68/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4771
- val_loss: 1.7065
- val_all_f1:  0.5568 0.5568 0.5568
- val_exp_f1:  0.8498 0.8498 0.8498
- val_non_f1:  0.2995 0.2991 0.2993

13056/13056 [==============================] - 68s - loss: 0.4759 - val_loss: 1.7065
Epoch 69/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4697
- val_loss: 1.6557
- val_all_f1:  0.5717 0.5717 0.5717
- val_exp_f1:  0.8649 0.8649 0.8649
- val_non_f1:  0.3142 0.3138 0.3140

13056/13056 [==============================] - 74s - loss: 0.4695 - val_loss: 1.6557
Epoch 70/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4697
- val_loss: 1.6643
- val_all_f1:  0.5717 0.5717 0.5717
- val_exp_f1:  0.8771 0.8771 0.8771
- val_non_f1:  0.3035 0.3031 0.3033

13056/13056 [==============================] - 72s - loss: 0.4703 - val_loss: 1.6643
Epoch 71/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3768
- val_loss: 1.7595
- val_all_f1:  0.5611 0.5611 0.5611
- val_exp_f1:  0.8422 0.8422 0.8422
- val_non_f1:  0.3142 0.3138 0.3140

13056/13056 [==============================] - 73s - loss: 0.3767 - val_loss: 1.7595
Epoch 72/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3890
- val_loss: 1.8183
- val_all_f1:  0.5639 0.5639 0.5639
- val_exp_f1:  0.8665 0.8665 0.8665
- val_non_f1:  0.2981 0.2977 0.2979

13056/13056 [==============================] - 70s - loss: 0.3878 - val_loss: 1.8183
Epoch 73/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4000
- val_loss: 1.7787
- val_all_f1:  0.5639 0.5639 0.5639
- val_exp_f1:  0.8558 0.8558 0.8558
- val_non_f1:  0.3075 0.3071 0.3073

13056/13056 [==============================] - 71s - loss: 0.4010 - val_loss: 1.7787
Epoch 74/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4008
- val_loss: 1.8011
- val_all_f1:  0.5384 0.5384 0.5384
- val_exp_f1:  0.8088 0.8088 0.8088
- val_non_f1:  0.3008 0.3004 0.3006

13056/13056 [==============================] - 71s - loss: 0.3995 - val_loss: 1.8011
Epoch 75/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4051
- val_loss: 1.7696
- val_all_f1:  0.5384 0.5384 0.5384
- val_exp_f1:  0.8285 0.8285 0.8285
- val_non_f1:  0.2834 0.2830 0.2832

13056/13056 [==============================] - 78s - loss: 0.4049 - val_loss: 1.7696
Epoch 76/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4151
- val_loss: 1.8135
- val_all_f1:  0.5504 0.5504 0.5504
- val_exp_f1:  0.8240 0.8240 0.8240
- val_non_f1:  0.3102 0.3097 0.3100

13056/13056 [==============================] - 73s - loss: 0.4142 - val_loss: 1.8135
Epoch 77/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4144
- val_loss: 1.8215
- val_all_f1:  0.5522 0.5518 0.5520
- val_exp_f1:  0.8404 0.8392 0.8398
- val_non_f1:  0.2991 0.2991 0.2991

13056/13056 [==============================] - 67s - loss: 0.4149 - val_loss: 1.8215
Epoch 78/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4197
- val_loss: 1.7817
- val_all_f1:  0.5518 0.5518 0.5518
- val_exp_f1:  0.8255 0.8255 0.8255
- val_non_f1:  0.3115 0.3111 0.3113

13056/13056 [==============================] - 70s - loss: 0.4203 - val_loss: 1.7817
Epoch 79/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.4445
- val_loss: 1.7674
- val_all_f1:  0.5568 0.5568 0.5568
- val_exp_f1:  0.8437 0.8437 0.8437
- val_non_f1:  0.3048 0.3044 0.3046

13056/13056 [==============================] - 73s - loss: 0.4435 - val_loss: 1.7674
Epoch 80/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3927
- val_loss: 1.7867
- val_all_f1:  0.5625 0.5625 0.5625
- val_exp_f1:  0.8619 0.8619 0.8619
- val_non_f1:  0.2991 0.2991 0.2991

13056/13056 [==============================] - 78s - loss: 0.3921 - val_loss: 1.7867
Epoch 81/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3250
- val_loss: 1.8462
- val_all_f1:  0.5551 0.5547 0.5549
- val_exp_f1:  0.8359 0.8346 0.8352
- val_non_f1:  0.3084 0.3084 0.3084

13056/13056 [==============================] - 78s - loss: 0.3262 - val_loss: 1.8462
Epoch 82/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3436
- val_loss: 1.8517
- val_all_f1:  0.5597 0.5597 0.5597
- val_exp_f1:  0.8589 0.8589 0.8589
- val_non_f1:  0.2968 0.2964 0.2966

13056/13056 [==============================] - 78s - loss: 0.3433 - val_loss: 1.8517
Epoch 83/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3616
- val_loss: 1.9120
- val_all_f1:  0.5518 0.5518 0.5518
- val_exp_f1:  0.8543 0.8543 0.8543
- val_non_f1:  0.2857 0.2857 0.2857

13056/13056 [==============================] - 68s - loss: 0.3610 - val_loss: 1.9120
Epoch 84/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3403
- val_loss: 1.8826
- val_all_f1:  0.5593 0.5589 0.5591
- val_exp_f1:  0.8404 0.8392 0.8398
- val_non_f1:  0.3124 0.3124 0.3124

13056/13056 [==============================] - 72s - loss: 0.3406 - val_loss: 1.8826
Epoch 85/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3669
- val_loss: 1.8794
- val_all_f1:  0.5313 0.5313 0.5313
- val_exp_f1:  0.8331 0.8331 0.8331
- val_non_f1:  0.2657 0.2657 0.2657

13056/13056 [==============================] - 74s - loss: 0.3670 - val_loss: 1.8794
Epoch 86/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3576
- val_loss: 1.8523
- val_all_f1:  0.5565 0.5561 0.5563
- val_exp_f1:  0.8556 0.8543 0.8550
- val_non_f1:  0.2937 0.2937 0.2937

13056/13056 [==============================] - 70s - loss: 0.3589 - val_loss: 1.8523
Epoch 87/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3710
- val_loss: 1.8861
- val_all_f1:  0.5490 0.5490 0.5490
- val_exp_f1:  0.8285 0.8285 0.8285
- val_non_f1:  0.3035 0.3031 0.3033

13056/13056 [==============================] - 73s - loss: 0.3700 - val_loss: 1.8861
Epoch 88/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3867
- val_loss: 1.8454
- val_all_f1:  0.5575 0.5575 0.5575
- val_exp_f1:  0.8422 0.8422 0.8422
- val_non_f1:  0.3075 0.3071 0.3073

13056/13056 [==============================] - 72s - loss: 0.3870 - val_loss: 1.8454
Epoch 89/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3815
- val_loss: 1.8399
- val_all_f1:  0.5526 0.5526 0.5526
- val_exp_f1:  0.8483 0.8483 0.8483
- val_non_f1:  0.2928 0.2924 0.2926

13056/13056 [==============================] - 65s - loss: 0.3812 - val_loss: 1.8399
Epoch 90/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3587
- val_loss: 1.8499
- val_all_f1:  0.5518 0.5518 0.5518
- val_exp_f1:  0.8346 0.8346 0.8346
- val_non_f1:  0.3035 0.3031 0.3033

13056/13056 [==============================] - 69s - loss: 0.3576 - val_loss: 1.8499
Epoch 91/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3021
- val_loss: 1.8984
- val_all_f1:  0.5455 0.5455 0.5455
- val_exp_f1:  0.8331 0.8331 0.8331
- val_non_f1:  0.2928 0.2924 0.2926

13056/13056 [==============================] - 72s - loss: 0.3022 - val_loss: 1.8984
Epoch 92/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3122
- val_loss: 1.9760
- val_all_f1:  0.5305 0.5305 0.5305
- val_exp_f1:  0.8103 0.8103 0.8103
- val_non_f1:  0.2848 0.2844 0.2846

13056/13056 [==============================] - 78s - loss: 0.3120 - val_loss: 1.9760
Epoch 93/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3189
- val_loss: 1.9606
- val_all_f1:  0.5352 0.5348 0.5350
- val_exp_f1:  0.8267 0.8255 0.8261
- val_non_f1:  0.2794 0.2790 0.2792

13056/13056 [==============================] - 75s - loss: 0.3185 - val_loss: 1.9606
Epoch 94/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3199
- val_loss: 1.9794
- val_all_f1:  0.5281 0.5277 0.5279
- val_exp_f1:  0.7918 0.7906 0.7912
- val_non_f1:  0.2968 0.2964 0.2966

13056/13056 [==============================] - 69s - loss: 0.3192 - val_loss: 1.9794
Epoch 95/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3431
- val_loss: 1.9724
- val_all_f1:  0.5316 0.5313 0.5314
- val_exp_f1:  0.8116 0.8103 0.8109
- val_non_f1:  0.2861 0.2857 0.2859

13056/13056 [==============================] - 73s - loss: 0.3428 - val_loss: 1.9724
Epoch 96/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3074
- val_loss: 1.9538
- val_all_f1:  0.5345 0.5341 0.5343
- val_exp_f1:  0.8207 0.8194 0.8200
- val_non_f1:  0.2834 0.2830 0.2832

13056/13056 [==============================] - 74s - loss: 0.3064 - val_loss: 1.9538
Epoch 97/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3270
- val_loss: 1.9369
- val_all_f1:  0.5320 0.5313 0.5316
- val_exp_f1:  0.8158 0.8134 0.8146
- val_non_f1:  0.2834 0.2830 0.2832

13056/13056 [==============================] - 76s - loss: 0.3271 - val_loss: 1.9369
Epoch 98/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3346
- val_loss: 1.9471
- val_all_f1:  0.5341 0.5334 0.5338
- val_exp_f1:  0.8250 0.8225 0.8237
- val_non_f1:  0.2794 0.2790 0.2792

13056/13056 [==============================] - 72s - loss: 0.3340 - val_loss: 1.9471
Epoch 99/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3452
- val_loss: 1.9874
- val_all_f1:  0.5395 0.5384 0.5389
- val_exp_f1:  0.8216 0.8179 0.8198
- val_non_f1:  0.2924 0.2924 0.2924

13056/13056 [==============================] - 71s - loss: 0.3456 - val_loss: 1.9874
Epoch 100/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3165
- val_loss: 1.9923
- val_all_f1:  0.5323 0.5320 0.5321
- val_exp_f1:  0.8116 0.8103 0.8109
- val_non_f1:  0.2874 0.2870 0.2872

13056/13056 [==============================] - 72s - loss: 0.3164 - val_loss: 1.9923
Epoch 101/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2756
- val_loss: 1.9920
- val_all_f1:  0.5458 0.5455 0.5456
- val_exp_f1:  0.8176 0.8164 0.8170
- val_non_f1:  0.3071 0.3071 0.3071

13056/13056 [==============================] - 73s - loss: 0.2761 - val_loss: 1.9920
Epoch 102/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2822
- val_loss: 2.0030
- val_all_f1:  0.5331 0.5320 0.5325
- val_exp_f1:  0.8216 0.8179 0.8198
- val_non_f1:  0.2804 0.2804 0.2804

13056/13056 [==============================] - 74s - loss: 0.2828 - val_loss: 2.0030
Epoch 103/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2913
- val_loss: 2.0277
- val_all_f1:  0.5477 0.5469 0.5473
- val_exp_f1:  0.8371 0.8346 0.8359
- val_non_f1:  0.2937 0.2937 0.2937

13056/13056 [==============================] - 72s - loss: 0.2919 - val_loss: 2.0277
Epoch 104/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2969
- val_loss: 2.0291
- val_all_f1:  0.5352 0.5341 0.5347
- val_exp_f1:  0.7973 0.7936 0.7954
- val_non_f1:  0.3057 0.3057 0.3057

13056/13056 [==============================] - 74s - loss: 0.2961 - val_loss: 2.0291
Epoch 105/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2997
- val_loss: 2.0550
- val_all_f1:  0.5341 0.5334 0.5338
- val_exp_f1:  0.8052 0.8027 0.8040
- val_non_f1:  0.2964 0.2964 0.2964

13056/13056 [==============================] - 69s - loss: 0.3029 - val_loss: 2.0550
Epoch 106/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2943
- val_loss: 2.0262
- val_all_f1:  0.5313 0.5305 0.5309
- val_exp_f1:  0.8113 0.8088 0.8100
- val_non_f1:  0.2861 0.2857 0.2859

13056/13056 [==============================] - 66s - loss: 0.2935 - val_loss: 2.0262
Epoch 107/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2938
- val_loss: 1.9913
- val_all_f1:  0.5451 0.5447 0.5449
- val_exp_f1:  0.8343 0.8331 0.8337
- val_non_f1:  0.2911 0.2911 0.2911

13056/13056 [==============================] - 66s - loss: 0.2934 - val_loss: 1.9913
Epoch 108/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2910
- val_loss: 2.0361
- val_all_f1:  0.5434 0.5426 0.5430
- val_exp_f1:  0.8189 0.8164 0.8176
- val_non_f1:  0.3017 0.3017 0.3017

13056/13056 [==============================] - 68s - loss: 0.2909 - val_loss: 2.0361
Epoch 109/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.3232
- val_loss: 2.0364
- val_all_f1:  0.5299 0.5291 0.5295
- val_exp_f1:  0.8037 0.8012 0.8024
- val_non_f1:  0.2897 0.2897 0.2897

13056/13056 [==============================] - 67s - loss: 0.3244 - val_loss: 2.0364
Epoch 110/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2839
- val_loss: 2.0647
- val_all_f1:  0.5384 0.5384 0.5384
- val_exp_f1:  0.8316 0.8316 0.8316
- val_non_f1:  0.2804 0.2804 0.2804

13056/13056 [==============================] - 77s - loss: 0.2835 - val_loss: 2.0647
Epoch 111/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2574
- val_loss: 2.1024
- val_all_f1:  0.5291 0.5291 0.5291
- val_exp_f1:  0.8149 0.8149 0.8149
- val_non_f1:  0.2781 0.2777 0.2779

13056/13056 [==============================] - 78s - loss: 0.2572 - val_loss: 2.1024
Epoch 112/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2651
- val_loss: 2.1510
- val_all_f1:  0.5178 0.5178 0.5178
- val_exp_f1:  0.7785 0.7785 0.7785
- val_non_f1:  0.2888 0.2884 0.2886

13056/13056 [==============================] - 73s - loss: 0.2641 - val_loss: 2.1510
Epoch 113/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2464
- val_loss: 2.1282
- val_all_f1:  0.5298 0.5298 0.5298
- val_exp_f1:  0.8179 0.8179 0.8179
- val_non_f1:  0.2767 0.2764 0.2766

13056/13056 [==============================] - 76s - loss: 0.2466 - val_loss: 2.1282
Epoch 114/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2798
- val_loss: 2.0969
- val_all_f1:  0.5338 0.5327 0.5332
- val_exp_f1:  0.8140 0.8103 0.8122
- val_non_f1:  0.2888 0.2884 0.2886

13056/13056 [==============================] - 69s - loss: 0.2804 - val_loss: 2.0969
Epoch 115/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2484
- val_loss: 2.1477
- val_all_f1:  0.5213 0.5206 0.5210
- val_exp_f1:  0.8082 0.8058 0.8070
- val_non_f1:  0.2697 0.2697 0.2697

13056/13056 [==============================] - 73s - loss: 0.2502 - val_loss: 2.1477
Epoch 116/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2841
- val_loss: 2.2020
- val_all_f1:  0.4957 0.4950 0.4954
- val_exp_f1:  0.7458 0.7436 0.7447
- val_non_f1:  0.2767 0.2764 0.2766

13056/13056 [==============================] - 77s - loss: 0.2848 - val_loss: 2.2020
Epoch 117/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2784
- val_loss: 2.1569
- val_all_f1:  0.5060 0.5057 0.5059
- val_exp_f1:  0.7827 0.7815 0.7821
- val_non_f1:  0.2634 0.2630 0.2632

13056/13056 [==============================] - 74s - loss: 0.2778 - val_loss: 2.1569
Epoch 118/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2902
- val_loss: 2.1028
- val_all_f1:  0.5192 0.5192 0.5192
- val_exp_f1:  0.8027 0.8027 0.8027
- val_non_f1:  0.2697 0.2697 0.2697

13056/13056 [==============================] - 71s - loss: 0.2909 - val_loss: 2.1028
Epoch 119/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2798
- val_loss: 2.1251
- val_all_f1:  0.5270 0.5270 0.5270
- val_exp_f1:  0.8149 0.8149 0.8149
- val_non_f1:  0.2741 0.2737 0.2739

13056/13056 [==============================] - 75s - loss: 0.2803 - val_loss: 2.1251
Epoch 120/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2760
- val_loss: 2.0872
- val_all_f1:  0.5338 0.5334 0.5336
- val_exp_f1:  0.8298 0.8285 0.8292
- val_non_f1:  0.2737 0.2737 0.2737

13056/13056 [==============================] - 70s - loss: 0.2758 - val_loss: 2.0872
Epoch 121/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2354
- val_loss: 2.2028
- val_all_f1:  0.4993 0.4986 0.4989
- val_exp_f1:  0.7747 0.7724 0.7736
- val_non_f1:  0.2580 0.2577 0.2578

13056/13056 [==============================] - 73s - loss: 0.2357 - val_loss: 2.2028
Epoch 122/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2406
- val_loss: 2.1515
- val_all_f1:  0.5234 0.5234 0.5234
- val_exp_f1:  0.8179 0.8179 0.8179
- val_non_f1:  0.2644 0.2644 0.2644

13056/13056 [==============================] - 76s - loss: 0.2416 - val_loss: 2.1515
Epoch 123/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2433
- val_loss: 2.2206
- val_all_f1:  0.5078 0.5078 0.5078
- val_exp_f1:  0.7982 0.7982 0.7982
- val_non_f1:  0.2523 0.2523 0.2523

13056/13056 [==============================] - 74s - loss: 0.2430 - val_loss: 2.2206
Epoch 124/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2535
- val_loss: 2.1576
- val_all_f1:  0.5188 0.5185 0.5187
- val_exp_f1:  0.8040 0.8027 0.8033
- val_non_f1:  0.2684 0.2684 0.2684

13056/13056 [==============================] - 72s - loss: 0.2535 - val_loss: 2.1576
Epoch 125/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2600
- val_loss: 2.1786
- val_all_f1:  0.5256 0.5256 0.5256
- val_exp_f1:  0.8073 0.8073 0.8073
- val_non_f1:  0.2781 0.2777 0.2779

13056/13056 [==============================] - 77s - loss: 0.2590 - val_loss: 2.1786
Epoch 126/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2536
- val_loss: 2.1736
- val_all_f1:  0.5263 0.5263 0.5263
- val_exp_f1:  0.7921 0.7921 0.7921
- val_non_f1:  0.2924 0.2924 0.2924

13056/13056 [==============================] - 72s - loss: 0.2540 - val_loss: 2.1736
Epoch 127/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2547
- val_loss: 2.1926
- val_all_f1:  0.5231 0.5227 0.5229
- val_exp_f1:  0.8100 0.8088 0.8094
- val_non_f1:  0.2710 0.2710 0.2710

13056/13056 [==============================] - 73s - loss: 0.2550 - val_loss: 2.1926
Epoch 128/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2721
- val_loss: 2.1951
- val_all_f1:  0.5174 0.5163 0.5169
- val_exp_f1:  0.7866 0.7830 0.7848
- val_non_f1:  0.2821 0.2817 0.2819

13056/13056 [==============================] - 73s - loss: 0.2736 - val_loss: 2.1951
Epoch 129/1000
12992/13056 [============================>.] - ETA: 0s - loss: 0.2686
- val_loss: 2.1346
- val_all_f1:  0.5260 0.5249 0.5254
- val_exp_f1:  0.8110 0.8073 0.8091
- val_non_f1:  0.2767 0.2764 0.2766

13056/13056 [==============================] - 69s - loss: 0.2683 - val_loss: 2.1346
[2018-03-12 14:05] training finished (ex/conll16st-vsimple-en)
[2018-03-12 14:05] best_val_loss: 25 - loss: 0.7559 - val_loss: 1.3510 - val_all_f1: 0.6072 - val_exp_f1: 0.9014 - val_non_f1: 0.3485
[2018-03-12 14:05] best_val_all_f1: 27 - loss: 0.7544 - val_loss: 1.3621 - val_all_f1: 0.6229 - val_exp_f1: 0.9120 - val_non_f1: 0.3685
